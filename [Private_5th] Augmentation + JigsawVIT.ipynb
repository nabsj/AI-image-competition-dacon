{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf24b99-346b-4525-aace-a036145c4ff7",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 및 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c548907c-0ba8-4300-aa33-50b3aba3a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import lightning as L\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops import rearrange\n",
    "from torchvision.io import read_image\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from timm.models.vision_transformer import Block, Attention, VisionTransformer\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from tqdm import tqdm\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1d8ac-7a99-43f4-8736-3e37bac8d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['seed']=40\n",
    "config['batch_size']=96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6b89b8-d525-4537-9779-ca1d54e3daa6",
   "metadata": {},
   "source": [
    "# 2. 데이터 준비 및 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f161aad-65be-4428-833b-e1743fdc53f7",
   "metadata": {},
   "source": [
    "## 2.1 Image Augmentation\n",
    "\n",
    "** 주의) 한번만 하는걸 추천, 어차피 JigsawDataset에서 매번 호출할때마다 재배열하는 코드있음!!\n",
    "\n",
    "** 주의) 한번만 하는걸 추천, 어차피 JigsawDataset에서 매번 호출할때마다 재배열하는 코드있음!!\n",
    "\n",
    "** 주의) 한번만 하는걸 추천, 어차피 JigsawDataset에서 매번 호출할때마다 재배열하는 코드있음!!\n",
    "\n",
    "** 주의) 한번만 하는걸 추천, 어차피 JigsawDataset에서 매번 호출할때마다 재배열하는 코드있음!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb21854-8fcd-44eb-89f1-80fe78898298",
   "metadata": {},
   "source": [
    "### 2.1.1 원본이미지 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a8aa9-8ee2-416f-949c-8305f7da57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(index, train_df):\n",
    "    sample_df = train_df.iloc[index]\n",
    "\n",
    "    train_path = sample_df['img_path'].split('/')[-1]\n",
    "    train_img = Image.open('./train/' + train_path)\n",
    "\n",
    "    width, height = train_img.size\n",
    "    cell_width = width // 4\n",
    "    cell_height = height // 4\n",
    "\n",
    "    target_positions = list(sample_df)[2:]\n",
    "\n",
    "    origin_img = Image.new(\"RGB\", (width, height))\n",
    "\n",
    "    # 각 타일을 올바른 위치로 이동\n",
    "    for target_pos in range(1, 17):\n",
    "        # 타일의 현재 위치 찾기\n",
    "        current_pos = target_positions.index(target_pos) + 1\n",
    "        current_row, current_col = divmod(current_pos - 1, 4)\n",
    "\n",
    "        # 타일의 목표 위치\n",
    "        target_row, target_col = divmod(target_pos - 1, 4)\n",
    "\n",
    "        # 타일을 추출\n",
    "        tile = train_img.crop((current_col * cell_width, current_row * cell_height, (current_col + 1) * cell_width, (current_row + 1) * cell_height))\n",
    "        # 타일을 올바른 위치에 붙여넣기\n",
    "        origin_img.paste(tile, (target_col * cell_width, target_row * cell_height))\n",
    "\n",
    "    # 재구성된 이미지 저장\n",
    "    origin_name = f'ORIGIN_{index:05}.jpg'\n",
    "    origin_path = './origin/' + origin_name\n",
    "    origin_img.save(origin_path)\n",
    "\n",
    "    return {'ID': origin_name, 'img_path': origin_path}\n",
    "\n",
    "def main(train_df):\n",
    "    num_processes = 16\n",
    "    pool = Pool(num_processes)\n",
    "\n",
    "    # tqdm\n",
    "    results = list(tqdm(pool.starmap(process_image, [(i, train_df) for i in range(len(train_df))]), total=len(train_df)))\n",
    "    \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    origin_df = pd.DataFrame(results)\n",
    "    origin_df.to_csv('./origin.csv', index=False)\n",
    "    print('./origin.csv 저장완료')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_df = pd.read_csv('./train.csv')  # 데이터 경로에 맞게 수정하세요\n",
    "    main(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eb91a8-513f-49f6-8a7e-9d5790ad5fdf",
   "metadata": {},
   "source": [
    "### 2.1.2 45도 rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b86b8-8118-45ea-bde5-2e8b23f0e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_and_shuffle_image_left_45(index, img_path):\n",
    "    # 원본 이미지 불러오기\n",
    "    img = Image.open(img_path)\n",
    "    orig_width, orig_height = img.size\n",
    "\n",
    "    # 이미지 좌로 45도 회전\n",
    "    img = img.rotate(45, expand=True)\n",
    "    rotated_width, rotated_height = img.size\n",
    "\n",
    "    # 회전한 이미지에서 중앙의 일정 영역을 크롭 (예: 300x300 픽셀)\n",
    "    crop_width, crop_height = 312, 312  # 크롭할 영역의 크기\n",
    "    left = (rotated_width - crop_width) // 2\n",
    "    top = (rotated_height - crop_height) // 2\n",
    "    right = (rotated_width + crop_width) // 2\n",
    "    bottom = (rotated_height + crop_height) // 2\n",
    "    img_cropped = img.crop((left, top, right, bottom))\n",
    "\n",
    "    # 크롭한 이미지를 원본 크기로 리사이징\n",
    "    img = img_cropped.resize((orig_width, orig_height), Image.LANCZOS)\n",
    "\n",
    "    # 확대된 이미지에서 원본 크기에 맞는 중앙 부분 잘라내기\n",
    "    new_width, new_height = img.size\n",
    "    left = (new_width - orig_width) / 2\n",
    "    top = (new_height - orig_height) / 2\n",
    "    right = (new_width + orig_width) / 2\n",
    "    bottom = (new_height + orig_height) / 2\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "\n",
    "    # 타일 추출 및 재배치\n",
    "    tiles = []\n",
    "    for i in range(16):\n",
    "        row, col = divmod(i, 4)\n",
    "        tile = img.crop((col * new_width // 4, row * new_height // 4, (col + 1) * new_width // 4, (row + 1) * new_height // 4))\n",
    "        tiles.append(tile)\n",
    "\n",
    "    # 타일 임의로 재배치\n",
    "    shuffled_indices = random.sample(range(16), 16)\n",
    "\n",
    "    # 재배치된 이미지 생성\n",
    "    shuffled_img = Image.new('RGB', (new_width, new_height))\n",
    "    for i, idx in enumerate(shuffled_indices):\n",
    "        row, col = divmod(i, 4)\n",
    "        shuffled_img.paste(tiles[idx], (col * new_width // 4, row * new_height // 4))\n",
    "\n",
    "    # 재배치된 이미지 저장\n",
    "    aug_name = f'augment_2_left_45_{index:05}.jpg'\n",
    "    aug_path = './augment_2_left_45/' + aug_name\n",
    "    shuffled_img.save(aug_path)\n",
    "\n",
    "    # 데이터프레임을 위한 정보 생성\n",
    "    data = {'ID': aug_name, 'img_path': aug_path}\n",
    "    for i, idx in enumerate(shuffled_indices, 1):\n",
    "        data[str(i)] = idx + 1  # 인덱스를 1부터 시작하도록 조정\n",
    "\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    origin_df = pd.read_csv('./origin.csv')  # 데이터 경로에 맞게 수정하세요\n",
    "    num_processes = 16  # 코어 수\n",
    "\n",
    "    with Pool(num_processes) as pool:\n",
    "        args = [(index, row['img_path']) for index, row in origin_df.iterrows()]\n",
    "        results = list(tqdm(pool.starmap(rotate_and_shuffle_image_left_45, args), total=len(origin_df)))\n",
    "\n",
    "    aug_df = pd.DataFrame(results)\n",
    "    aug_df.to_csv('./augment_2_left_45.csv', index=False)\n",
    "    print('./augment_2_left_45.csv 저장완료')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c00ae7-6931-4863-bf84-ca9e03fbe76e",
   "metadata": {},
   "source": [
    "### 2.1.3 90도 rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e86c4c8-8c64-4180-b72f-fea160d02534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_and_shuffle_image(index, img_path):\n",
    "    # 원본 이미지 불러오기\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # 이미지 좌로 90도 회전\n",
    "    img = img.rotate(90, expand=True)\n",
    "\n",
    "    width, height = img.size\n",
    "    cell_width = width // 4\n",
    "    cell_height = height // 4\n",
    "\n",
    "    # 타일 추출 및 재배치\n",
    "    tiles = []\n",
    "    for i in range(16):\n",
    "        row, col = divmod(i, 4)\n",
    "        tile = img.crop((col * cell_width, row * cell_height, (col + 1) * cell_width, (row + 1) * cell_height))\n",
    "        tiles.append(tile)\n",
    "\n",
    "    # 타일 임의로 재배치\n",
    "    shuffled_indices = random.sample(range(16), 16)\n",
    "\n",
    "    # 재배치된 이미지 생성\n",
    "    shuffled_img = Image.new('RGB', (width, height))\n",
    "    for i, idx in enumerate(shuffled_indices):\n",
    "        row, col = divmod(i, 4)\n",
    "        shuffled_img.paste(tiles[idx], (col * cell_width, row * cell_height))\n",
    "\n",
    "    # 재배치된 이미지 저장\n",
    "    aug_name = f'augment_2_left_90_{index:05}.jpg'\n",
    "    aug_path = './augment_2_left_90/' + aug_name\n",
    "    shuffled_img.save(aug_path)\n",
    "\n",
    "    # 데이터프레임을 위한 정보 생성\n",
    "    data = {'ID': aug_name, 'img_path': aug_path}\n",
    "    for i, idx in enumerate(shuffled_indices, 1):\n",
    "        data[str(i)] = idx + 1  # 인덱스를 1부터 시작하도록 조정\n",
    "\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    origin_df = pd.read_csv('./origin.csv')  # 데이터 경로에 맞게 수정하세요\n",
    "    num_processes = 16  # 코어 수\n",
    "\n",
    "    with Pool(num_processes) as pool:\n",
    "        args = [(index, row['img_path']) for index, row in origin_df.iterrows()]\n",
    "        results = list(tqdm(pool.starmap(rotate_and_shuffle_image, args), total=len(origin_df)))\n",
    "\n",
    "    aug_df = pd.DataFrame(results)\n",
    "    aug_df.to_csv('./augment_2_left_90.csv', index=False)\n",
    "    print('./augment_2_left_90.csv 저장완료')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c15cc-2f15-4f62-a4ae-def3e5846f4e",
   "metadata": {},
   "source": [
    "### 2.1.4 135도 rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50f96c-50a4-4957-bea1-d3aa34e8517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_and_shuffle_image_left_135(index, img_path):\n",
    "    # 원본 이미지 불러오기\n",
    "    img = Image.open(img_path)\n",
    "    orig_width, orig_height = img.size\n",
    "\n",
    "    # 이미지 좌로 45도 회전\n",
    "    img = img.rotate(135, expand=True)\n",
    "    rotated_width, rotated_height = img.size\n",
    "\n",
    "    # 회전한 이미지에서 중앙의 일정 영역을 크롭 (예: 300x300 픽셀)\n",
    "    crop_width, crop_height = 312, 312  # 크롭할 영역의 크기\n",
    "    left = (rotated_width - crop_width) // 2\n",
    "    top = (rotated_height - crop_height) // 2\n",
    "    right = (rotated_width + crop_width) // 2\n",
    "    bottom = (rotated_height + crop_height) // 2\n",
    "    img_cropped = img.crop((left, top, right, bottom))\n",
    "\n",
    "    # 크롭한 이미지를 원본 크기로 리사이징\n",
    "    img = img_cropped.resize((orig_width, orig_height), Image.LANCZOS)\n",
    "\n",
    "    # 확대된 이미지에서 원본 크기에 맞는 중앙 부분 잘라내기\n",
    "    new_width, new_height = img.size\n",
    "    left = (new_width - orig_width) / 2\n",
    "    top = (new_height - orig_height) / 2\n",
    "    right = (new_width + orig_width) / 2\n",
    "    bottom = (new_height + orig_height) / 2\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "\n",
    "    # 타일 추출 및 재배치\n",
    "    tiles = []\n",
    "    for i in range(16):\n",
    "        row, col = divmod(i, 4)\n",
    "        tile = img.crop((col * new_width // 4, row * new_height // 4, (col + 1) * new_width // 4, (row + 1) * new_height // 4))\n",
    "        tiles.append(tile)\n",
    "\n",
    "    # 타일 임의로 재배치\n",
    "    shuffled_indices = random.sample(range(16), 16)\n",
    "\n",
    "    # 재배치된 이미지 생성\n",
    "    shuffled_img = Image.new('RGB', (new_width, new_height))\n",
    "    for i, idx in enumerate(shuffled_indices):\n",
    "        row, col = divmod(i, 4)\n",
    "        shuffled_img.paste(tiles[idx], (col * new_width // 4, row * new_height // 4))\n",
    "\n",
    "    # 재배치된 이미지 저장\n",
    "    aug_name = f'augment_2_left_135_{index:05}.jpg'\n",
    "    aug_path = './augment_2_left_135/' + aug_name\n",
    "    shuffled_img.save(aug_path)\n",
    "\n",
    "    # 데이터프레임을 위한 정보 생성\n",
    "    data = {'ID': aug_name, 'img_path': aug_path}\n",
    "    for i, idx in enumerate(shuffled_indices, 1):\n",
    "        data[str(i)] = idx + 1  # 인덱스를 1부터 시작하도록 조정\n",
    "\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    origin_df = pd.read_csv('./origin.csv')  # 데이터 경로에 맞게 수정하세요\n",
    "    num_processes = 16  # 코어 수\n",
    "\n",
    "    with Pool(num_processes) as pool:\n",
    "        args = [(index, row['img_path']) for index, row in origin_df.iterrows()]\n",
    "        results = list(tqdm(pool.starmap(rotate_and_shuffle_image_left_135, args), total=len(origin_df)))\n",
    "\n",
    "    aug_df = pd.DataFrame(results)\n",
    "    aug_df.to_csv('./augment_2_left_135.csv', index=False)\n",
    "    print('./augment_2_left_135.csv 저장완료')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12318fbb-a325-4ea0-8869-73bc9f12c170",
   "metadata": {},
   "source": [
    "### 2.1.5 180도 rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e2031b-c453-4348-baf2-7b7461b54258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_and_shuffle_image_180(index, img_path):\n",
    "    # 원본 이미지 불러오기\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # 이미지 180도 회전\n",
    "    img = img.rotate(180, expand=True)  # 180도 회전\n",
    "\n",
    "\n",
    "    width, height = img.size\n",
    "    cell_width = width // 4\n",
    "    cell_height = height // 4\n",
    "\n",
    "    # 타일 추출 및 재배치\n",
    "    tiles = []\n",
    "    for i in range(16):\n",
    "        row, col = divmod(i, 4)\n",
    "        tile = img.crop((col * cell_width, row * cell_height, (col + 1) * cell_width, (row + 1) * cell_height))\n",
    "        tiles.append(tile)\n",
    "\n",
    "    # 타일 임의로 재배치\n",
    "    shuffled_indices = random.sample(range(16), 16)\n",
    "\n",
    "    # 재배치된 이미지 생성\n",
    "    shuffled_img = Image.new('RGB', (width, height))\n",
    "    for i, idx in enumerate(shuffled_indices):\n",
    "        row, col = divmod(i, 4)\n",
    "        shuffled_img.paste(tiles[idx], (col * cell_width, row * cell_height))\n",
    "    \n",
    "    aug_name = f'augment_2_180_{index:05}.jpg'\n",
    "    aug_path = './augment_2_180/' + aug_name\n",
    "    shuffled_img.save(aug_path)\n",
    "\n",
    "    # 데이터프레임을 위한 정보 생성\n",
    "    data = {'ID': aug_name, 'img_path': aug_path}\n",
    "    for i, idx in enumerate(shuffled_indices, 1):\n",
    "        data[str(i)] = idx + 1  # 인덱스를 1부터 시작하도록 조정\n",
    "\n",
    "    return data\n",
    "\n",
    "def main_180():\n",
    "    origin_df = pd.read_csv('./origin.csv')\n",
    "    num_processes = 16  # 코어 수\n",
    "\n",
    "    with Pool(num_processes) as pool:\n",
    "        args = [(index, row['img_path']) for index, row in origin_df.iterrows()]\n",
    "        results = list(tqdm(pool.starmap(rotate_and_shuffle_image_180, args), total=len(origin_df)))\n",
    "\n",
    "    aug_df = pd.DataFrame(results)\n",
    "    aug_df.to_csv('./augment_2_180.csv', index=False)\n",
    "    print('./augment_2_180.csv 저장완료')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main_180()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c463201-e0af-4396-abac-15da6f698e6c",
   "metadata": {},
   "source": [
    "### 2.1.6 225도 rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3edb991-3d26-48b0-8d01-a9a788f4d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_and_shuffle_image_right_135(index, img_path):\n",
    "    # 원본 이미지 불러오기\n",
    "    img = Image.open(img_path)\n",
    "    orig_width, orig_height = img.size\n",
    "\n",
    "    # 이미지 좌로 45도 회전\n",
    "    img = img.rotate(-135, expand=True)\n",
    "    rotated_width, rotated_height = img.size\n",
    "\n",
    "    # 회전한 이미지에서 중앙의 일정 영역을 크롭 (예: 300x300 픽셀)\n",
    "    crop_width, crop_height = 312, 312  # 크롭할 영역의 크기\n",
    "    left = (rotated_width - crop_width) // 2\n",
    "    top = (rotated_height - crop_height) // 2\n",
    "    right = (rotated_width + crop_width) // 2\n",
    "    bottom = (rotated_height + crop_height) // 2\n",
    "    img_cropped = img.crop((left, top, right, bottom))\n",
    "\n",
    "    # 크롭한 이미지를 원본 크기로 리사이징\n",
    "    img = img_cropped.resize((orig_width, orig_height), Image.LANCZOS)\n",
    "\n",
    "    # 확대된 이미지에서 원본 크기에 맞는 중앙 부분 잘라내기\n",
    "    new_width, new_height = img.size\n",
    "    left = (new_width - orig_width) / 2\n",
    "    top = (new_height - orig_height) / 2\n",
    "    right = (new_width + orig_width) / 2\n",
    "    bottom = (new_height + orig_height) / 2\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "\n",
    "    # 타일 추출 및 재배치\n",
    "    tiles = []\n",
    "    for i in range(16):\n",
    "        row, col = divmod(i, 4)\n",
    "        tile = img.crop((col * new_width // 4, row * new_height // 4, (col + 1) * new_width // 4, (row + 1) * new_height // 4))\n",
    "        tiles.append(tile)\n",
    "\n",
    "    # 타일 임의로 재배치\n",
    "    shuffled_indices = random.sample(range(16), 16)\n",
    "\n",
    "    # 재배치된 이미지 생성\n",
    "    shuffled_img = Image.new('RGB', (new_width, new_height))\n",
    "    for i, idx in enumerate(shuffled_indices):\n",
    "        row, col = divmod(i, 4)\n",
    "        shuffled_img.paste(tiles[idx], (col * new_width // 4, row * new_height // 4))\n",
    "\n",
    "    # 재배치된 이미지 저장\n",
    "    aug_name = f'augment_2_right_135_{index:05}.jpg'\n",
    "    aug_path = './augment_2_right_135/' + aug_name\n",
    "    shuffled_img.save(aug_path)\n",
    "\n",
    "    # 데이터프레임을 위한 정보 생성\n",
    "    data = {'ID': aug_name, 'img_path': aug_path}\n",
    "    for i, idx in enumerate(shuffled_indices, 1):\n",
    "        data[str(i)] = idx + 1  # 인덱스를 1부터 시작하도록 조정\n",
    "\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    origin_df = pd.read_csv('./origin.csv')  # 데이터 경로에 맞게 수정하세요\n",
    "    num_processes = 16  # 코어 수\n",
    "\n",
    "    with Pool(num_processes) as pool:\n",
    "        args = [(index, row['img_path']) for index, row in origin_df.iterrows()]\n",
    "        results = list(tqdm(pool.starmap(rotate_and_shuffle_image_right_135, args), total=len(origin_df)))\n",
    "\n",
    "    aug_df = pd.DataFrame(results)\n",
    "    aug_df.to_csv('./augment_2_right_135.csv', index=False)\n",
    "    print('./augment_2_right_135.csv 저장완료')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e8ba2c-eef9-4992-8bb7-4b0e09d94fbd",
   "metadata": {},
   "source": [
    "### 2.1.7 270도 rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558cda65-99ca-4e9b-910c-5b1e97f47cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_and_shuffle_image_right_90(index, img_path):\n",
    "    # 원본 이미지 불러오기\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # 이미지 오른쪽으로 90도 회전\n",
    "    img = img.rotate(-90, expand=True)  # 오른쪽으로 90도 회전\n",
    "\n",
    "    width, height = img.size\n",
    "    cell_width = width // 4\n",
    "    cell_height = height // 4\n",
    "\n",
    "    # 타일 추출 및 재배치\n",
    "    tiles = []\n",
    "    for i in range(16):\n",
    "        row, col = divmod(i, 4)\n",
    "        tile = img.crop((col * cell_width, row * cell_height, (col + 1) * cell_width, (row + 1) * cell_height))\n",
    "        tiles.append(tile)\n",
    "\n",
    "    # 타일 임의로 재배치\n",
    "    shuffled_indices = random.sample(range(16), 16)\n",
    "\n",
    "    # 재배치된 이미지 생성\n",
    "    shuffled_img = Image.new('RGB', (width, height))\n",
    "    for i, idx in enumerate(shuffled_indices):\n",
    "        row, col = divmod(i, 4)\n",
    "        shuffled_img.paste(tiles[idx], (col * cell_width, row * cell_height))\n",
    "    \n",
    "    aug_name = f'augment_2_right_90_{index:05}.jpg'\n",
    "    aug_path = './augment_2_right_90/' + aug_name\n",
    "    shuffled_img.save(aug_path)\n",
    "\n",
    "    # 데이터프레임을 위한 정보 생성\n",
    "    data = {'ID': aug_name, 'img_path': aug_path}\n",
    "    for i, idx in enumerate(shuffled_indices, 1):\n",
    "        data[str(i)] = idx + 1  # 인덱스를 1부터 시작하도록 조정\n",
    "\n",
    "    return data\n",
    "\n",
    "def main_right_90():\n",
    "    origin_df = pd.read_csv('./origin.csv')\n",
    "    num_processes = 16  # 코어 수\n",
    "\n",
    "    with Pool(num_processes) as pool:\n",
    "        args = [(index, row['img_path']) for index, row in origin_df.iterrows()]\n",
    "        results = list(tqdm(pool.starmap(rotate_and_shuffle_image_right_90, args), total=len(origin_df)))\n",
    "\n",
    "    aug_df = pd.DataFrame(results)\n",
    "    aug_df.to_csv('./augment_2_right_90.csv', index=False)\n",
    "    print('./augment_2_right_90.csv 저장완료')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main_right_90()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fe5893-041e-489a-81a0-ad4d63b26aa0",
   "metadata": {},
   "source": [
    "### 2.1.9 315도 rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776c44d-dabb-4dc5-a69d-1f38c4352d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def rotate_and_shuffle_image_right_45(index, img_path):\n",
    "    # 원본 이미지 불러오기\n",
    "    img = Image.open(img_path)\n",
    "    orig_width, orig_height = img.size\n",
    "\n",
    "    # 이미지 좌로 45도 회전\n",
    "    img = img.rotate(-45, expand=True)\n",
    "    rotated_width, rotated_height = img.size\n",
    "\n",
    "    # 회전한 이미지에서 중앙의 일정 영역을 크롭 (예: 300x300 픽셀)\n",
    "    crop_width, crop_height = 312, 312  # 크롭할 영역의 크기\n",
    "    left = (rotated_width - crop_width) // 2\n",
    "    top = (rotated_height - crop_height) // 2\n",
    "    right = (rotated_width + crop_width) // 2\n",
    "    bottom = (rotated_height + crop_height) // 2\n",
    "    img_cropped = img.crop((left, top, right, bottom))\n",
    "\n",
    "    # 크롭한 이미지를 원본 크기로 리사이징\n",
    "    img = img_cropped.resize((orig_width, orig_height), Image.LANCZOS)\n",
    "\n",
    "    # 확대된 이미지에서 원본 크기에 맞는 중앙 부분 잘라내기\n",
    "    new_width, new_height = img.size\n",
    "    left = (new_width - orig_width) / 2\n",
    "    top = (new_height - orig_height) / 2\n",
    "    right = (new_width + orig_width) / 2\n",
    "    bottom = (new_height + orig_height) / 2\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "\n",
    "    # 타일 추출 및 재배치\n",
    "    tiles = []\n",
    "    for i in range(16):\n",
    "        row, col = divmod(i, 4)\n",
    "        tile = img.crop((col * new_width // 4, row * new_height // 4, (col + 1) * new_width // 4, (row + 1) * new_height // 4))\n",
    "        tiles.append(tile)\n",
    "\n",
    "    # 타일 임의로 재배치\n",
    "    shuffled_indices = random.sample(range(16), 16)\n",
    "\n",
    "    # 재배치된 이미지 생성\n",
    "    shuffled_img = Image.new('RGB', (new_width, new_height))\n",
    "    for i, idx in enumerate(shuffled_indices):\n",
    "        row, col = divmod(i, 4)\n",
    "        shuffled_img.paste(tiles[idx], (col * new_width // 4, row * new_height // 4))\n",
    "\n",
    "    # 재배치된 이미지 저장\n",
    "    aug_name = f'augment_2_right_45_{index:05}.jpg'\n",
    "    aug_path = './augment_2_right_45/' + aug_name\n",
    "    shuffled_img.save(aug_path)\n",
    "\n",
    "    # 데이터프레임을 위한 정보 생성\n",
    "    data = {'ID': aug_name, 'img_path': aug_path}\n",
    "    for i, idx in enumerate(shuffled_indices, 1):\n",
    "        data[str(i)] = idx + 1  # 인덱스를 1부터 시작하도록 조정\n",
    "\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    origin_df = pd.read_csv('./origin.csv')  # 데이터 경로에 맞게 수정하세요\n",
    "    num_processes = 16  # 코어 수\n",
    "\n",
    "    with Pool(num_processes) as pool:\n",
    "        args = [(index, row['img_path']) for index, row in origin_df.iterrows()]\n",
    "        results = list(tqdm(pool.starmap(rotate_and_shuffle_image_right_45, args), total=len(origin_df)))\n",
    "\n",
    "    aug_df = pd.DataFrame(results)\n",
    "    aug_df.to_csv('./augment_2_right_45.csv', index=False)\n",
    "    print('./augment_2_right_45.csv 저장완료')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313bfdf7-56eb-4106-b8f3-e52fabd41796",
   "metadata": {},
   "source": [
    "## 2.2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c756e222-90be-4eab-9283-bbfe1826b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternate_rows(df1, df2,df3,df4,df5, df6,df7,df8):\n",
    "    # 새로운 데이터 프레임을 위한 빈 리스트 초기화\n",
    "    merged_rows = []\n",
    "\n",
    "    # 두 데이터 프레임의 각 행을 번갈아가며 추가\n",
    "    for i in range(len(df1)):\n",
    "        merged_rows.append(df1.iloc[i])\n",
    "        merged_rows.append(df2.iloc[i])\n",
    "        merged_rows.append(df3.iloc[i])\n",
    "        merged_rows.append(df4.iloc[i])\n",
    "        merged_rows.append(df5.iloc[i])\n",
    "        merged_rows.append(df6.iloc[i])\n",
    "        merged_rows.append(df7.iloc[i])\n",
    "        merged_rows.append(df8.iloc[i])\n",
    "\n",
    "    # 리스트를 데이터 프레임으로 변환\n",
    "    merged_df = pd.DataFrame(merged_rows).reset_index(drop=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb42816-5998-4313-ad48-aa96f048892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and split datasets\n",
    "train_df = pd.read_csv('./train.csv')\n",
    "aug_df_left_45 =  pd.read_csv('./augment_2_left_45.csv')\n",
    "aug_df_left_90 = pd.read_csv('./augment_2_left_90.csv')\n",
    "aug_df_left_135 = pd.read_csv('./augment_2_left_135.csv')\n",
    "aug_df_180 = pd.read_csv('./augment_2_180.csv')\n",
    "aug_df_right_45 = pd.read_csv('./augment_2_right_45.csv')\n",
    "aug_df_right_90 = pd.read_csv('./augment_2_right_90.csv')\n",
    "aug_df_right_135 = pd.read_csv('./augment_2_right_135.csv')\n",
    "train_df = alternate_rows(train_df,\n",
    "                          aug_df_left_45,\n",
    "                          aug_df_left_90,\n",
    "                          aug_df_left_135,\n",
    "                          aug_df_180,\n",
    "                          aug_df_right_45,\n",
    "                          aug_df_right_90,\n",
    "                          aug_df_right_135\n",
    "                         )\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=config['seed'])\n",
    "\n",
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6305525-87e2-498f-82d9-51ec0425e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_df = alternate_rows(train_df, aug_df_left_90, aug_df_180, aug_df_right_90)\n",
    "train_df2 = pd.read_csv('./train.csv')\n",
    "train_df2 = train_df2.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "val_df_left_90 = aug_df_left_90.sample(n)\n",
    "val_df_180 = aug_df_180.sample(n)\n",
    "val_df_right_90 = aug_df_right_90.sample(n + remainder)\n",
    "val_df2 = pd.concat([val_df_left_90, val_df_180, val_df_right_90], ignore_index=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44924c2a-ce76-403e-bc60-c813d154a2b8",
   "metadata": {},
   "source": [
    "# 3. 커스텀 데이터셋 및 데이터 로더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0080ffe4-5648-4f33-af4a-2ec44bf95281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퍼즐 이미지 데이터셋을 위한 커스텀 데이터셋 클래스입니다.\n",
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, df, data_path, mode='train'):\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            row = self.df.iloc[idx]\n",
    "            image = read_image(row['img_path'])\n",
    "            shuffle_order = row[[str(i) for i in range(1, 17)]].values-1\n",
    "            image_src = self.reset_image(image, shuffle_order)\n",
    "            image_reshuffle, reshuffle_order = self.shuffle_image(image_src)\n",
    "            adjacency_matrix = self.get_adjacency_matrix(reshuffle_order)\n",
    "            data = {\n",
    "                'image_src':image_src,\n",
    "                'image_reshuffle':image_reshuffle,\n",
    "                'order':reshuffle_order,\n",
    "                'adjacency_matrix':adjacency_matrix,\n",
    "                'score': self.get_score(range(16), reshuffle_order),\n",
    "            }\n",
    "            return data\n",
    "            \n",
    "        elif self.mode == 'val':\n",
    "            row = self.df.iloc[idx]\n",
    "            image = read_image(row['img_path']).numpy()\n",
    "            shuffle_order = row[[str(i) for i in range(1, 17)]].values-1\n",
    "            adjacency_matrix = self.get_adjacency_matrix(shuffle_order.tolist())\n",
    "            data = {\n",
    "                'image':image,\n",
    "                'order':shuffle_order,\n",
    "                'adjacency_matrix':adjacency_matrix,\n",
    "            }\n",
    "            return data\n",
    "            \n",
    "        elif self.mode == 'inference':\n",
    "            row = self.df.iloc[idx]\n",
    "            image = read_image(row['img_path']).numpy()\n",
    "            data = {\n",
    "                'image':image\n",
    "            }\n",
    "            return data\n",
    "\n",
    "    def reset_image(self, image, shuffle_order):     # 이미지를 초기 상태(원본 순서)로 재배열\n",
    "        c, h, w = image.shape\n",
    "        block_h, block_w = h//4, w//4\n",
    "        image_src = [[0 for _ in range(4)] for _ in range(4)]\n",
    "        for idx, order in enumerate(shuffle_order):\n",
    "            h_idx, w_idx = divmod(order,4)\n",
    "            h_idx_shuffle, w_idx_shuffle = divmod(idx, 4)\n",
    "            image_src[h_idx][w_idx] = image[:, block_h * h_idx_shuffle : block_h * (h_idx_shuffle+1), block_w * w_idx_shuffle : block_w * (w_idx_shuffle+1)]\n",
    "        image_src = np.concatenate([np.concatenate(image_row, -1) for image_row in image_src], -2)\n",
    "        return image_src\n",
    "\n",
    "    def shuffle_image(self, image):     # 이미지를 랜덤하게 섞음\n",
    "        c, h, w = image.shape\n",
    "        block_h, block_w = h//4, w//4\n",
    "        shuffle_order = list(range(0, 16))\n",
    "        random.shuffle(shuffle_order)\n",
    "        image_shuffle = [[0 for _ in range(4)] for _ in range(4)]\n",
    "        for idx, order in enumerate(shuffle_order):\n",
    "            h_idx, w_idx = divmod(order,4)\n",
    "            h_idx_shuffle, w_idx_shuffle = divmod(idx, 4)\n",
    "            image_shuffle[h_idx_shuffle][w_idx_shuffle] = image[:, block_h * h_idx : block_h * (h_idx+1), block_w * w_idx : block_w * (w_idx+1)]\n",
    "        image_shuffle = np.concatenate([np.concatenate(image_row, -1) for image_row in image_shuffle], -2)\n",
    "        return image_shuffle, shuffle_order\n",
    "\n",
    "    def get_adjacency_matrix(self, order): # 패치에 대하여 연결된 패치 찾기  # 인접 행렬을 생성, 퍼즐 조각 간의 연결 상태\n",
    "        order_matrix = [order[4*i:4*(i+1)]for i in range(4)]\n",
    "        adj_matrix = np.zeros((16,16), dtype=int)\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                o = order_matrix[i][j]\n",
    "                i_o, j_o = divmod(o,4)\n",
    "                for i_add,j_add in [(-1,0), (1,0), (0,1), (0,-1)]:\n",
    "                    i_compare, j_compare = i_o+i_add, j_o+j_add\n",
    "                    if i_compare<0 or i_compare>=4 or j_compare<0 or j_compare>=4 : continue\n",
    "                    o_compare = order[i_compare*4+j_compare]\n",
    "                    i_, j_ = i*4+j, order.index(i_compare*4+j_compare)\n",
    "                    if (i_add,j_add) == (-1,0):\n",
    "                        adj_matrix[i_][j_] = 1 # 상\n",
    "                        adj_matrix[j_][i_] = 2 # 하\n",
    "                    elif (i_add,j_add) == (-1,0):\n",
    "                        adj_matrix[i_][j_] = 2\n",
    "                        adj_matrix[j_][i_] = 1\n",
    "                    elif  (i_add,j_add) == (0,-1):\n",
    "                        adj_matrix[i_][j_] = 3 # 좌\n",
    "                        adj_matrix[j_][i_] = 4 # 우\n",
    "                    elif (i_add,j_add) == (0,1):\n",
    "                        adj_matrix[i_][j_] = 4\n",
    "                        adj_matrix[j_][i_] = 3\n",
    "        return adj_matrix\n",
    "\n",
    "    def get_score(self, order_true, order_pred): # regression task? 현재 아키텍처와 맞지 않을듯 # 평가산식 점수 계산\n",
    "        puzzle_a = np.array(order_true, dtype=int).reshape(4, 4)\n",
    "        puzzle_s = np.array(order_pred, dtype=int).reshape(4, 4)\n",
    "\n",
    "        accuracies = {}\n",
    "        accuracies['1x1'] = np.mean(puzzle_a == puzzle_s)\n",
    "\n",
    "        combinations_2x2 = [(i, j) for i in range(3) for j in range(3)]\n",
    "        combinations_3x3 = [(i, j) for i in range(2) for j in range(2)]\n",
    "\n",
    "        for size in range(2, 5):  # Loop through sizes 2, 3, 4\n",
    "            correct_count = 0  # Initialize counter for correct full sub-puzzles\n",
    "            total_subpuzzles = 0\n",
    "            combinations = combinations_2x2 if size == 2 else combinations_3x3 if size == 3 else [(0, 0)]\n",
    "            for start_row, start_col in combinations:\n",
    "                rows = slice(start_row, start_row + size)\n",
    "                cols = slice(start_col, start_col + size)\n",
    "                if np.array_equal(puzzle_a[rows, cols], puzzle_s[rows, cols]):\n",
    "                    correct_count += 1\n",
    "                total_subpuzzles += 1\n",
    "\n",
    "            accuracies[f'{size}x{size}'] = correct_count / total_subpuzzles\n",
    "\n",
    "        score = (accuracies['1x1'] + accuracies['2x2'] + accuracies['3x3'] + accuracies['4x4']) / 4.\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd0ec5-b402-4d1b-8bb8-cf821556e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩 과정에서 배치 데이터를 처리하기 위한 레이트 함수입니다.\n",
    "class JigsawCollateFn:\n",
    "    def __init__(self, transform, mode):\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, batch):     # 배치 데이터를 받아서 필요한 처리를 수행하고 텐서로 반환\n",
    "        if self.mode=='train':\n",
    "            pixel_values = torch.stack([self.transform(Image.fromarray(data['image_reshuffle'].astype(np.uint8).transpose(1,2,0))) for data in batch])\n",
    "            order = torch.tensor([data['order'] for data in batch], dtype=torch.long)\n",
    "            adjacency_matrices = [data['adjacency_matrix'] for data in batch]\n",
    "            adjacency_matrx = torch.tensor(np.array(adjacency_matrices), dtype=torch.long)\n",
    "        \n",
    "            return {\n",
    "                'pixel_values':pixel_values,\n",
    "                'order':order,\n",
    "                'adjacency_matrx':adjacency_matrx\n",
    "            }\n",
    "        elif self.mode=='val':\n",
    "            pixel_values = torch.stack([self.transform(Image.fromarray(data['image'].astype(np.uint8).transpose(1,2,0))) for data in batch])\n",
    "            order = torch.tensor([data['order'] for data in batch], dtype=torch.long)\n",
    "            adjacency_matrices = [data['adjacency_matrix'] for data in batch]\n",
    "            adjacency_matrx = torch.tensor(np.array(adjacency_matrices), dtype=torch.long)\n",
    "            return {\n",
    "                'pixel_values':pixel_values,\n",
    "                'order':order,\n",
    "                'adjacency_matrx':adjacency_matrx\n",
    "            }\n",
    "        elif self.mode=='inference':\n",
    "            pixel_values = torch.stack([self.transform(Image.fromarray(data['image'].astype(np.uint8).transpose(1,2,0))) for data in batch])\n",
    "            return {\n",
    "                'pixel_values':pixel_values,\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70f306d-6d6d-4093-8e72-28bcdfdcf45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(256,256), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "]) #Imagenet, normalize 차용\n",
    "\n",
    "train_dataset = JigsawDataset(df=train_df, data_path='', mode='train')\n",
    "val_dataset = JigsawDataset(df=val_df, data_path='', mode='val')\n",
    "pred_dataset = JigsawDataset(df=test_df,data_path='',mode='inference')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=JigsawCollateFn(transform, 'train'), batch_size=config['batch_size'],\n",
    "                              num_workers = 16, prefetch_factor=3)\n",
    "val_dataloader = DataLoader(val_dataset, collate_fn=JigsawCollateFn(transform, 'val'), batch_size=config['batch_size'],\n",
    "                            num_workers = 16 , prefetch_factor=3)\n",
    "pred_dataloader = DataLoader(pred_dataset, collate_fn=JigsawCollateFn(transform, 'inference'), batch_size=config['batch_size'],\n",
    "                             num_workers = 16 , prefetch_factor=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26f2f98-3e76-4046-b7be-4d07aeb2061a",
   "metadata": {},
   "source": [
    "# 4. Model architecture 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c2eebb-d203-4d88-8a67-c1ccb3356d61",
   "metadata": {},
   "source": [
    "## 4.1. Vision Transformer (ViT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed0fd6-abf7-439b-8249-32c79bcd19ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_forward(self, x, attn_bias=None):\n",
    "    B, N, C = x.shape\n",
    "    qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
    "    q, k, v = qkv.unbind(0)\n",
    "    q, k = self.q_norm(q), self.k_norm(k)\n",
    "\n",
    "    q = q * self.scale\n",
    "    attn = q @ k.transpose(-2, -1)\n",
    "    if attn_bias is not None:\n",
    "        attn + attn_bias\n",
    "    attn = attn.softmax(dim=-1)\n",
    "    attn = self.attn_drop(attn)\n",
    "    x = attn @ v\n",
    "\n",
    "    x = x.transpose(1, 2).reshape(B, N, C)\n",
    "    x = self.proj(x)\n",
    "    x = self.proj_drop(x)\n",
    "    return x\n",
    "Attention.forward = attention_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee51406a-853b-4c78-b36d-0f6e3e1f80aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_forward(self, x_and_attn_bias):\n",
    "    x, attn_bias = x_and_attn_bias\n",
    "    x = x + self.drop_path1(self.ls1(self.attn(self.norm1(x), attn_bias)))\n",
    "    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))\n",
    "    return (x, attn_bias)\n",
    "Block.forward = block_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c982b-e74c-483c-a78f-4c45e2c36d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vision_transformer_forward_features(self, x, embed_bias=None, attn_bias=None):\n",
    "    x = self.patch_embed(x)\n",
    "    x = self._pos_embed(x)\n",
    "    if embed_bias is not None:\n",
    "        x = x + embed_bias\n",
    "    x = self.patch_drop(x)\n",
    "    x = self.norm_pre(x)\n",
    "    x, _ = self.blocks((x,attn_bias))\n",
    "    x = self.norm(x)\n",
    "    return x\n",
    "VisionTransformer.forward_features = vision_transformer_forward_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f553e-a52a-4c52-8e73-82b6e5107a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vision_transformer_forward(self, x, embed_bias=None, attn_bias=None):\n",
    "    x = self.forward_features(x, embed_bias, attn_bias)\n",
    "    return x\n",
    "VisionTransformer.forward = vision_transformer_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d4d5e9-3880-439b-bce4-9a6e2f1e9a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('vit_medium_patch16_gap_256', pretrained=True, num_classes=0)\n",
    "\n",
    "model_config = {\n",
    "    'image_size':256,\n",
    "    'patch_size':16,\n",
    "    'hidden_size':512,\n",
    "    'num_attention_heads':8,\n",
    "}\n",
    "\n",
    "transform_config = timm.data.resolve_data_config(model.pretrained_cfg)\n",
    "transform_config.pop('crop_pct')\n",
    "transform_config.pop('crop_mode')\n",
    "\n",
    "transform = timm.data.create_transform(\n",
    "    **transform_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40671a-cc52-4ad6-8315-dcd38273d0a1",
   "metadata": {},
   "source": [
    "## 4.2. JigsawElectra 모델 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560b690-9104-4bfe-89c4-b54ecebf60dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jigsaw 퍼즐 문제를 해결하기 위한 커스텀 모델 아키텍처입니다.\n",
    "class JigsawElectra(nn.Module):\n",
    "    \"\"\"\n",
    "    모델설명\n",
    "    1st Stage:\n",
    "    In the initial stage, a transformer architecture is employed to discern optimal patch arrangements for each puzzle segment.\n",
    "    This involves intricate spatial relationships, where the model dynamically identifies neighboring patches in cardinal directions(i.e., up, down, left, right).\n",
    "    The foundation of this stage lies in the incorporation of attention matrices at the final layer, providing nuanced insights into patch interdependencies.\n",
    "    - 초기 단계에서는 트랜스포머 아키텍처를 사용하여 각 퍼즐 조각에 대한 최적의 패치 배치를 파악합니다.\n",
    "    - 모델은 동적으로 인접 패치를 카디널 방향(위, 아래, 왼쪽, 오른쪽)으로 식별하여 복잡한 공간 관계를 다룹니다.\n",
    "    - 이 단계의 기반이 되는 것은 마지막 레이어에 있는 attention matrices 통해 패치 간의 상호 의존성에 대한 세밀한 통찰력을 제공하는 것입니다.\n",
    "\n",
    "    \n",
    "    2nd Stage:\n",
    "    Subsequently, the second stage capitalizes on the predicted matrices from the initial stage to derive piece-type embeddings and connect-type embedding.\n",
    "    These embeddings encapsulate diverse spatial configurations, such as cross shapes, left corners and right, and else.\n",
    "    The innovation lies in the integration of piece-type embeddings as positional embedding biases, enhancing the model's contextual awareness.\n",
    "    Furthermore, connect matrix embeddings serve as attention biases, enabling the model to capture intricate inter-piece relationships.\n",
    "    The final objective of this stage is to predict an optimal reordering sequence, leveraging the acquired embeddings.\n",
    "    - 이어서, 두 번째 단계에서는 초기 단계에서 예측된 매트릭스를 활용하여 조각 타입 임베딩(piece-type embeddings)과 연결 타입 임베딩(connect-type embedding)을 도출합니다.\n",
    "    - 이러한 임베딩들은 십자형, 왼쪽 코너와 오른쪽 코너 등과 같은 다양한 공간 구성을 포함합니다.\n",
    "    - 이 단계의 혁신은 조각 타입 임베딩을 위치 임베딩 바이어스로 통합하여 모델의 문맥 인식을 향상시키는 것입니다.\n",
    "    - 또한, 연결 매트릭스 임베딩은 주의 바이어스로서 작용하여 모델이 조각 간의 복잡한 관계를 포착할 수 있게 합니다.\n",
    "    - 이 단계의 최종 목표는 획득한 임베딩을 활용하여 최적의 재배열 순서를 예측하는 것입니다.\n",
    "\n",
    "    \n",
    "    The backbone model shares weights excluding head layers. And losses are jointly computed for gradient updates, aiming for efficient learning and high performance.\n",
    "    - 백본 모델은 헤드 레이어를 제외하고 가중치를 공유합니다., 손실은 효율적인 학습과 높은 성능을 목표로 공동으로 계산됩니다.\n",
    "    \"\"\"\n",
    "    # 초기화 메소드, 모델과 설정을 초기화합니다.\n",
    "    def __init__(self, model, config):\n",
    "        super(JigsawElectra, self).__init__()\n",
    "        for k,v in config.items():\n",
    "            setattr(self,k,v)\n",
    "        self.attention_head_size = int(self.hidden_size / self.num_attention_heads)\n",
    "        self.num_patch_per_block = int(self.image_size/4/self.patch_size)\n",
    "        self.model = model\n",
    "        \n",
    "        self.pos_emb = nn.Parameter(torch.randn(16, self.hidden_size))\n",
    "        self.piece_type_emb = nn.Embedding(10, self.hidden_size, padding_idx=0)\n",
    "        self.piece_type_emb.weight.data[0,:]=0\n",
    "        self.piece_type_emb.weight.data = self.piece_type_emb.weight.data*0.1\n",
    "        self.connect_type_emb = nn.Embedding(5, self.num_attention_heads, padding_idx=0)\n",
    "        self.connect_type_emb.weight.data[0,:]=0\n",
    "        self.connect_type_emb.weight.data = self.connect_type_emb.weight.data*0.1\n",
    "        \n",
    "        self.local_linear1 = nn.LazyLinear(self.hidden_size)\n",
    "        self.local_linear2 = nn.LazyLinear(self.hidden_size)\n",
    "        self.local_conv = nn.Conv2d(self.num_attention_heads, self.num_attention_heads, int(self.image_size/16), int(self.image_size/16))\n",
    "        self.local_clf = nn.Sequential(\n",
    "            nn.LazyLinear(self.num_attention_heads),\n",
    "            nn.Tanh(),\n",
    "            nn.LazyLinear(5),\n",
    "        )\n",
    "\n",
    "        self.global_conv = nn.Conv1d(self.hidden_size, self.hidden_size, int(self.image_size/16), int(self.image_size/16))\n",
    "        self.global_clf = nn.Sequential(\n",
    "            nn.LazyLinear(self.hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.LazyLinear(16),\n",
    "        )\n",
    "\n",
    "    def _transpose(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(new_x_shape)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        b, h, l, d = x.shape\n",
    "        x = torch.cat(x.reshape(b, h, -1, self.num_patch_per_block, d).split(self.num_patch_per_block, 2), 3).reshape(b, h, l, d)\n",
    "        return x\n",
    "\n",
    "    # local 단계\n",
    "    def local_forward(self, x, label=None):\n",
    "        pos_emb = self.pos_emb.reshape(4,4,-1)\n",
    "        pos_emb = pos_emb.unsqueeze(-2).repeat(1,1,self.num_patch_per_block,1).reshape(4,-1,self.hidden_size)\n",
    "        pos_emb = pos_emb.unsqueeze(1).repeat(1,self.num_patch_per_block, 1, 1).reshape(-1, 4*self.num_patch_per_block, self.hidden_size)\n",
    "        pos_emb = pos_emb.reshape(-1, self.hidden_size)\n",
    "        \n",
    "        x = self.model(x, embed_bias=pos_emb)\n",
    "        x1 = self._transpose(self.local_linear1(x))\n",
    "        x2 = self._transpose(self.local_linear2(x))\n",
    "        x = torch.matmul(x1,x2.transpose(-1, -2)).transpose(-1,-2)\n",
    "        x = self.local_conv(x)\n",
    "        x = x.permute(0,2,3,1)\n",
    "        x = self.local_clf(x)\n",
    "        probs = nn.Softmax(dim=-1)(x)\n",
    "        loss = None\n",
    "        if label is not None:\n",
    "            loss = nn.CrossEntropyLoss()(x.reshape(-1, 5), label.reshape(-1))\n",
    "        return x, probs, loss\n",
    "\n",
    "    # global 단계, 전체 이미지에 대한 이해를 바탕으로 최종 퍼즐 순서를 예측합니다.\n",
    "    def global_forward(self, x, piece_type=None, connect_type=None, label=None):\n",
    "        pos_emb = self.pos_emb.reshape(4,4,-1)\n",
    "        pos_emb = pos_emb.unsqueeze(-2).repeat(1,1,self.num_patch_per_block,1).reshape(4,-1,self.hidden_size)\n",
    "        pos_emb = pos_emb.unsqueeze(1).repeat(1,self.num_patch_per_block, 1, 1).reshape(-1, 4*self.num_patch_per_block, self.hidden_size)\n",
    "        pos_emb = pos_emb.reshape(-1, self.hidden_size)\n",
    "        \n",
    "        if piece_type is not None:\n",
    "            b = piece_type.shape[0]\n",
    "            piece_emb = self.piece_type_emb(piece_type).reshape(b, 4, 4, -1)\n",
    "            piece_emb = piece_emb.unsqueeze(-2).repeat(1,1,1,self.num_patch_per_block,1).reshape(b, 4,-1,self.hidden_size)\n",
    "            piece_emb = piece_emb.unsqueeze(2).repeat(1,1,self.num_patch_per_block, 1, 1).reshape(b,-1, 4*self.num_patch_per_block, self.hidden_size)\n",
    "            piece_emb = piece_emb.reshape(b,-1, self.hidden_size)\n",
    "            pos_emb = piece_emb+pos_emb\n",
    "            \n",
    "        attn_bias = None\n",
    "        if connect_type is not None:\n",
    "            b = connect_type.shape[0]\n",
    "            attn_bias = self.connect_type_emb(connect_type) # B 16,16,8\n",
    "            attn_bias = attn_bias.unsqueeze(-2).repeat(1,1,1,int(self.image_size/16),1).reshape(b,16,-1,self.num_attention_heads)\n",
    "            attn_bias = attn_bias.unsqueeze(2).repeat(1,1,int(self.image_size/16), 1, 1).reshape(b,-1, self.image_size, self.num_attention_heads)\n",
    "            attn_bias = attn_bias.permute(0,3,1,2)\n",
    "            \n",
    "        x = self.model(\n",
    "            x,\n",
    "            embed_bias=pos_emb,\n",
    "            attn_bias=attn_bias,\n",
    "        )\n",
    "        x = self._transpose(x)\n",
    "        b, h, l, d = x.shape\n",
    "        x = x.permute(0,1,3,2).reshape(b,h*d,l)\n",
    "        x = self.global_conv(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.global_clf(x)\n",
    "        probs = nn.Softmax(dim=-1)(x)\n",
    "        \n",
    "        loss = None\n",
    "        if label is not None:\n",
    "            loss = nn.CrossEntropyLoss()(x.reshape(-1, 16), label.reshape(-1))\n",
    "        return x, probs, loss "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20793fd8-d647-494b-a451-dc6d7ac85723",
   "metadata": {},
   "source": [
    "# 5. PyTorch Lightning 모듈 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969f8f3-7abd-4e2f-8359-e595052c4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Lightning을 사용한 트레이닝, 검증, 추론을 위한 클래스입니다.\n",
    "class LitJigsawElectra(L.LightningModule):\n",
    "    def __init__(self, model, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.jigsaw_electra = JigsawElectra(model, config)\n",
    "        self.inference_iter = 1\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=1e-6)     # 학습률 조정\n",
    "        return opt\n",
    "\n",
    "    # 트레이닝 스텝\n",
    "    def training_step(self, batch):\n",
    "        x_local, x_local_probs, loss_local = self.jigsaw_electra.local_forward(batch['pixel_values'], batch['adjacency_matrx'])        \n",
    "        connect_type = x_local_probs.argmax(-1).detach()\n",
    "        piece_type = self.connect_to_piece(connect_type).detach()\n",
    "        x_global, x_global_probs, loss_global = self.jigsaw_electra.global_forward(batch['pixel_values'], piece_type=piece_type, connect_type=connect_type, label=batch['order'])\n",
    "        loss = loss_local*0.2 + loss_global\n",
    "        self.log(\"train_loss_local\", loss_local, on_step=True, on_epoch=False)\n",
    "        self.log(\"train_loss_global\", loss_global, on_step=True, on_epoch=False)\n",
    "        return loss\n",
    "\n",
    "    # 검증 스텝\n",
    "    def validation_step(self, batch):\n",
    "        x_local, x_local_probs, loss_local = self.jigsaw_electra.local_forward(batch['pixel_values'], batch['adjacency_matrx'])\n",
    "        self.log(\"val_loss_local\", loss_local)\n",
    "        connect_type = x_local_probs.argmax(-1).detach()\n",
    "        piece_type = self.connect_to_piece(connect_type).detach()\n",
    "        local_accuracy = torch.mean(1*(connect_type == batch['adjacency_matrx']), dtype=torch.float32)\n",
    "        self.log(\"val_acc_local\", local_accuracy)\n",
    "        x_global, x_global_probs, loss_global = self.jigsaw_electra.global_forward(batch['pixel_values'], piece_type=piece_type, connect_type=connect_type, label=batch['order'])\n",
    "        self.log(\"val_loss_global\", loss_global)\n",
    "        self.validation_step_outputs.append((x_global_probs, batch['order']))\n",
    "        return\n",
    "\n",
    "    # 추론 스텝\n",
    "    def predict_step(self, batch):\n",
    "        pixel_values = batch['pixel_values']\n",
    "        label = batch.get('order', None)\n",
    "        for i in range(self.inference_iter):\n",
    "            x_local, x_local_probs, _ = self.jigsaw_electra.local_forward(pixel_values)        \n",
    "            connect_type = x_local_probs.argmax(-1).detach()\n",
    "            piece_type = self.connect_to_piece(connect_type).detach()\n",
    "            x_global, x_global_probs, _ = self.jigsaw_electra.global_forward(batch['pixel_values'], piece_type=piece_type, connect_type=connect_type)\n",
    "            reorder = self._probs_to_order(x_global_probs)\n",
    "            pixel_values = self._reorder_image(pixel_values, reorder)\n",
    "        return x_global_probs, reorder, label\n",
    "\n",
    "    # 연결 타입(connect types)을 기반으로 조각 타입(piece types)을 결정합니다.\n",
    "    def connect_to_piece(self, connect_types):\n",
    "        device = connect_types.device\n",
    "        connect_types = connect_types.detach().cpu()\n",
    "        piece_types = []\n",
    "        for connect_type in connect_types:\n",
    "            piece_type = []\n",
    "            for connect_type_row in connect_type:\n",
    "                connect_bins = torch.bincount(connect_type_row)\n",
    "                if torch.equal(connect_bins[1:5], torch.LongTensor([0,1,0,1])): #  ┌\n",
    "                    piece_type.append(1)\n",
    "                elif torch.equal(connect_bins[1:5], torch.LongTensor([0,1,1,1])): # ㅜ\n",
    "                    piece_type.append(2)\n",
    "                elif torch.equal(connect_bins[1:5], torch.LongTensor([0,1,1,0])): # ㄱ\n",
    "                    piece_type.append(3)\n",
    "                elif torch.equal(connect_bins[1:5], torch.LongTensor([1,1,0,1])): # ㅏ\n",
    "                    piece_type.append(4)\n",
    "                elif torch.equal(connect_bins[1:5], torch.LongTensor([1,1,1,0])): # ㅓ\n",
    "                    piece_type.append(5)\n",
    "                elif torch.equal(connect_bins[1:5], torch.LongTensor([1,0,0,1])): # ㄴ\n",
    "                    piece_type.append(6)\n",
    "                elif torch.equal(connect_bins[1:5], torch.LongTensor([1,0,1,1])): # ㅗ\n",
    "                    piece_type.append(7)\n",
    "                elif torch.equal(connect_bins[1:5], torch.LongTensor([1,0,1,0])): # ┘\n",
    "                    piece_type.append(8)\n",
    "                elif torch.equal(connect_bins[1:5], torch.LongTensor([1,1,1,1])): # +\n",
    "                    piece_type.append(9)\n",
    "                else: # unknown\n",
    "                    piece_type.append(0)\n",
    "            piece_types.append(piece_type)\n",
    "        piece_types = torch.LongTensor(piece_types).to(device)\n",
    "        return piece_types\n",
    "\n",
    "    # 전체 검증 성능을 계산하고 로깅\n",
    "    def on_validation_epoch_end(self):\n",
    "        order_pred = []\n",
    "        order_true = []\n",
    "        for probs, order in self.validation_step_outputs:\n",
    "            order_pred.append(self._probs_to_order(probs))\n",
    "            order_true.append(order)\n",
    "        order_pred = torch.cat(order_pred).detach().cpu().numpy()\n",
    "        order_true = torch.cat(order_true).detach().cpu().numpy()\n",
    "        \n",
    "        score, accuracies = self._get_score(order_true, order_pred)\n",
    "    \n",
    "        # 다양한 퍼즐 크기에 대한 정확도를 로깅합니다\n",
    "        self.log(\"val_score_1x1\", accuracies['1x1'])\n",
    "        self.log(\"val_score_2x2\", accuracies['2x2'])\n",
    "        self.log(\"val_score_3x3\", accuracies['3x3'])\n",
    "        self.log(\"val_score_4x4\", accuracies['4x4'])\n",
    "        self.log(\"val_score\", score)\n",
    "        \n",
    "        self.validation_step_outputs.clear()\n",
    "        return\n",
    "\n",
    "    # 주어진 실제 순서(order_true)와 예측 순서(order_pred)에 기반하여 점수를 계산\n",
    "    def _get_score(self, order_true, order_pred):\n",
    "        combinations_2x2 = [(i, j) for i in range(3) for j in range(3)]\n",
    "        combinations_3x3 = [(i, j) for i in range(2) for j in range(2)]\n",
    "        accuracies = {}\n",
    "        accuracies['1x1'] = np.mean(order_true == order_pred)\n",
    "        \n",
    "        for size in range(2, 5): \n",
    "            correct_count = 0  \n",
    "            total_subpuzzles = 0\n",
    "            for i in range(len(order_true)):\n",
    "                puzzle_a = order_true[i].reshape(4, 4)\n",
    "                puzzle_s = order_pred[i].reshape(4, 4)\n",
    "                combinations = combinations_2x2 if size == 2 else combinations_3x3 if size == 3 else [(0, 0)]\n",
    "                for start_row, start_col in combinations:\n",
    "                    rows = slice(start_row, start_row + size)\n",
    "                    cols = slice(start_col, start_col + size)\n",
    "                    if np.array_equal(puzzle_a[rows, cols], puzzle_s[rows, cols]):\n",
    "                        correct_count += 1\n",
    "                    total_subpuzzles += 1\n",
    "            accuracies[f'{size}x{size}'] = correct_count / total_subpuzzles\n",
    "        score = (accuracies['1x1'] + accuracies['2x2'] + accuracies['3x3'] + accuracies['4x4']) / 4.\n",
    "        return score, accuracies\n",
    "\n",
    "    # 확률(probs)을 기반으로 최적의 퍼즐 조각 순서를 결정\n",
    "    def _probs_to_order(self, probs): # Greedily arrange the jigsaw puzzle pieces based on maximum probability.\n",
    "        order = []\n",
    "        for prob in probs:\n",
    "            prob = prob.reshape(16,16).clone()\n",
    "            indices = [-1 for _ in range(16)]\n",
    "            for _ in range(16):\n",
    "                i, j = divmod(int(prob.argmax()),16)\n",
    "                indices[i]=j\n",
    "                prob[i, :] = float('-inf')\n",
    "                prob[:, j] = float('-inf')\n",
    "            order.append(indices)\n",
    "        order = torch.LongTensor(order)\n",
    "        return order\n",
    "\n",
    "    # 주어진 순서에 따라 이미지를 재배열\n",
    "    def _reorder_image(self, images, reorders):\n",
    "        device = images.device\n",
    "        images_reordered = []\n",
    "        for image, reorder in zip(images, reorders):\n",
    "            image = image.cpu().numpy()\n",
    "            reorder = reorder.cpu().numpy()\n",
    "            c, h, w = image.shape\n",
    "            block_h, block_w = h // 4, w // 4\n",
    "            image_src = np.zeros((c, h, w), dtype=image.dtype)\n",
    "            for idx, order in enumerate(reorder):\n",
    "                h_idx, w_idx = divmod(order, 4)\n",
    "                h_idx_shuffle, w_idx_shuffle = divmod(idx, 4)\n",
    "                image_src[:, block_h * h_idx : block_h * (h_idx + 1), block_w * w_idx : block_w * (w_idx + 1)] = image[:, block_h * h_idx_shuffle : block_h * (h_idx_shuffle + 1), block_w * w_idx_shuffle : block_w * (w_idx_shuffle + 1)]\n",
    "            images_reordered.append(image_src)\n",
    "        \n",
    "        images_reordered = np.stack(images_reordered)\n",
    "        images_reordered = torch.from_numpy(images_reordered).to(device)\n",
    "        return images_reordered\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3125a-2b87-465c-8b19-cc456ec46dd0",
   "metadata": {},
   "source": [
    "# 6. Trainer 설정 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7135d6d7-72bb-4657-96b6-f008ddf5b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_score',\n",
    "    mode='max',\n",
    "    dirpath='./checkpoint3_aug/',\n",
    "    filename='jigsawelectra-vitgap-{epoch:02d}-{val_score:.6f}',\n",
    "    save_top_k=3,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e500d-9323-4d29-9bc2-2c4022d37ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping_callback = EarlyStopping(monitor=\"val_score\", mode=\"max\", patience=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5e70f-20b9-44a7-8939-e217eed77b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_jigsaw_electra = LitJigsawElectra(model, model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d226352-b69c-4174-ad28-3262eaae1801",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_jigsaw_electra = LitJigsawElectra.load_from_checkpoint('./checkpoint3_aug/jigsawelectra-vitgap-epoch=11-val_score=0.994698.ckpt',model=model, config=model_config)\n",
    "lit_jigsaw_electra.inference_iter=1 #1e-6 사용 점수 0.9920312059 02-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e0b27-efed-4b07-ab09-4cb636fa96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard Logger 설정\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"24-02-05\")\n",
    "\n",
    "L.seed_everything(config['seed'])\n",
    "trainer = L.Trainer(max_epochs=150, precision='bf16-mixed', callbacks=[checkpoint_callback, earlystopping_callback], logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e2895d-2728-40c3-9209-227a999aded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경고 메시지를 무시하고 싶은 경우\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message=\"Creating a tensor from a list of numpy.ndarrays is extremely slow.*\")\n",
    "\n",
    "trainer.fit(lit_jigsaw_electra, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25f3018-1781-4a35-b003-06a84c99d40a",
   "metadata": {},
   "source": [
    "# 7. 모델 평가 및 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487736ab-e320-4d8c-9805-8c0fdd63ef36",
   "metadata": {},
   "source": [
    "## 7.1 Model evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a726ad-896e-4869-bf83-a2a53c017d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_jigsaw_electra = LitJigsawElectra.load_from_checkpoint('./checkpoint3_aug/jigsawelectra-vitgap-epoch=11-val_score=0.994698.ckpt',model=model, config=model_config)\n",
    "lit_jigsaw_electra.inference_iter=1 #1e-6 사용 점수 0.9920312059 02-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b765544-8170-4a9b-b512-79d974eddccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745621d0-f2f1-44c8-8a90-4e6be1e42079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경고 메시지를 무시하고 싶은 경우\n",
    "warnings.filterwarnings('ignore', category=UserWarning, message=\"Creating a tensor from a list of numpy.ndarrays is extremely slow.*\")\n",
    "\n",
    "val_preds = trainer.predict(lit_jigsaw_electra, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c4c76-d9d0-4d92-922b-7b0c79169f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_order_pred = torch.cat([order_pred for pixel_values, order_pred, order_true in val_preds]).cpu().numpy()\n",
    "val_order_true = torch.cat([order_true for pixel_values, order_pred, order_true in val_preds]).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc6e37-8819-423d-a5a9-37515e93ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_jigsaw_electra._get_score(val_order_true, val_order_pred) \n",
    "# inference_iter=1 늘린다고 좋아지지 않음. pretrained image clf 를 이용하여 선별적으로 iterative하게 하면 더 좋아질지도."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7e9eb-cdf4-450b-8a43-2f7e07b3a1fb",
   "metadata": {},
   "source": [
    "## 7.2 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d45889-e77a-42f6-9530-0464561c789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(lit_jigsaw_electra, pred_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4adf78f-55e3-42b1-9071-7e4788606965",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_pred = torch.cat([order_pred for pixel_values, order_pred, _ in preds]).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f534b-a856-4e90-a286-0368d905bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59501479-216c-4a7a-9558-10706376273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.iloc[:,1:] = order_pred + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a379d63-7912-49f4-aa33-2df097a8fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submission/24-02-05-1_submission1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
